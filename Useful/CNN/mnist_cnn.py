# -*- coding: utf-8 -*-
"""MNIST CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18yDK01XO96y18rnKWsETb-fD3Cd_PBH5
"""

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.models import Model
from keras.layers import Dropout
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Flatten                    #flatten Data within our NN
from keras.layers.convolutional import Conv2D       #to implement Convolutional Layer
from keras.layers.convolutional import MaxPooling2D #to implement Pooling Layer
import random

#same as before from here------------------------------------------------------
np.random.seed(0)




(X_train, y_train), (X_test, y_test)= mnist.load_data()
 
print(X_train.shape)
print(X_test.shape)
assert(X_train.shape[0] == y_train.shape[0]), "The number of images is not equal to the number of labels."
assert(X_train.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."
assert(X_test.shape[0] == y_test.shape[0]), "The number of images is not equal to the number of labels."
assert(X_test.shape[1:] == (28,28)), "The dimensions of the images are not 28 x 28."
 
num_of_samples=[]
 
cols = 5
num_classes = 10
 
fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,10))
fig.tight_layout()
 
for i in range(cols):
    for j in range(num_classes):
      x_selected = X_train[y_train == j]
      axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))
      axs[j][i].axis("off")
      if i == 2:
        axs[j][i].set_title(str(j))
        num_of_samples.append(len(x_selected))




print(num_of_samples)
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Distribution of the train dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")
plt.show()
 
#until here ------------------------------------------------------

X_train = X_train.reshape(60000, 28, 28, 1) #now X_train and X_test dont't have to be flattened to become 1D, depth is one since we are using gray scale
X_test = X_test.reshape(10000, 28, 28, 1) 


y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
 
X_train = X_train/255
X_test = X_test/255

#define LeNet model
def Lenet():
  model = Sequential()
  model.add(Conv2D(30, (5,5), input_shape= (28,28,1), activation = 'relu')) #first one is amount of filters (depth), second one is filter shape
  #afterwards shpae is 24x24
  # model.add(Conv2D(30, (5,5), input_shape= (28,28,1), activation = 'relu',stride =, padding =)) with the standard layer used above strides=1, padding ='valid' are set automatically
  model.add(MaxPooling2D(pool_size=(2,2))) #2x2 filter taking max value
  #afterwards shape is 12x12
  model.add(Conv2D(15, (3,3), input_shape= (28,28,1), activation = 'relu')) #more parameters than in first C layer (780),
  # due to the 30 feature maps we need to apply them to 15x30x3x3 #15 bias Paramters
  model.add(MaxPooling2D(pool_size=(2,2))) #resulting in 5x5 image
  #now we need to flatten the data to feed into the Fully Connected Layer
  model.add(Flatten())
  model.add(Dense(500,activation ='relu'))
  model.add(Dropout(0.5)) #dropout layer 
  model.add(Dense(num_classes,activation = 'softmax'))
  model.compile(Adam(lr=0.01),loss = 'categorical_crossentropy', metrics = ['accuracy'])
  return model

model = Lenet()
print(model.summary())
h = model.fit(X_train, y_train,epochs = 10, validation_split=0.1,batch_size = 400, verbose = 1, shuffle = 'true-')

#from the old code:
plt.plot(h.history['loss'],label= 'Training Loss')
plt.plot(h.history['val_loss'],label= 'Validation Loss')
plt.legend()
plt.title('Loss')
plt.xlabel('Epoch')

# In[119]:


import requests
import cv2
from PIL import Image
#download 
url = ['https://www.researchgate.net/profile/Jose_Sempere/publication/221258631/figure/fig1/AS:305526891139075@1449854695342/Handwritten-digit-2.png', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcST8KzXHtkSHcxzdpnllMhAj0upLEwnNFdtY6j4YUPcmaf4Ty3u' ]
for i in url:
 response = requests.get(i,stream = True)
 img = Image.open(response.raw)
 plt.imshow(img)
 img_array = np.asarray(img) #converts to array
 resized = cv2.resize(img_array,(28,28)) #resize to 28x28 so we can evaluate it
 gray_img = cv2.cvtColor(resized,cv2.COLOR_BGR2GRAY)  #convert to single color channel like in finding_lanes
 #notice that the background is 255 and the number is 0 which has to be changed as the NN was trained for the opposite
 image = cv2.bitwise_not(gray_img) #use bitwise operation to change colors
 plt.imshow(image,cmap  = plt.get_cmap("gray"))
 #same as before
 image = image.reshape(1,28,28,1) #only line we have to change from previous implementation
 prediction = model.predict_classes(image)
 print('Prediction is:',prediction)

# In[118]:


score = model.evaluate(X_test,y_test,verbose = 0)
print(type(score)) #returns list
print('Test score :',score[0])
print('Test accuracy :',score[1])

#plot feature maps
layer1 = Model(inputs = model.layers[0].input, outputs = model.layers[0].output) #first Convolutional layer  
layer2 = Model(inputs = model.layers[0].input, outputs = model.layers[2].output) #second Convolutional layer (3rd total layer)

visual_layer1 = layer1.predict(image)
visual_layer2 = layer2.predict(image)
print(visual_layer1.shape)
print(visual_layer2.shape)

plt.figure(figsize=(10,6))
#1st layer
print("1st layer maps : ")
for i in range(30):
  plt.subplot(6,5,i+1) #grid with 6 rows and 5 columns, put i+1th image at appropriate position
  plt.imshow(visual_layer1[0, :,:,i],cmap= plt.get_cmap('jet'))
  plt.axis('off')


#2nd layer notably more unrecognizable, as filters become more complex
plt.figure(figsize=(10,6))

for i in range(15):
  plt.subplot(5,3,i+1) #grid with 6 rows and 5 columns, put i+1th image at appropriate position
  plt.imshow(visual_layer1[0, :,:,i],cmap= plt.get_cmap('jet'))
  plt.axis('off')