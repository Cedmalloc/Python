# -*- coding: utf-8 -*-
"""Traffic Signs Starter Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YW_g-uuM6AQtr8_WZLiNY7D7INLYtMKa
"""

import numpy as np
import matplotlib.pyplot as plt
import keras
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
import pickle
import random

!git clone https://bitbucket.org/jadslim/german-traffic-signs  #import German traffic sign set from bitbucket by cloning 
!ls german-traffic-signs  #shows us that 1 csv and three pickled files are in this path

np.random.seed(0)

with open('german-traffic-signs/train.p','rb') as f:   #closes file automatically for us // 'rb' because we are reading from the file
  train = pickle.load(f)  #unpickled data

with open('german-traffic-signs/valid.p','rb') as f:
  val = pickle.load(f)  #unpickled data

with open('german-traffic-signs/test.p','rb') as f:
  test = pickle.load(f)  #unpickled data
  
#print(type(train)) shows us that it is a dicitionary
x_train, y_train = train['features'] ,train['labels']  #labels for classes, features = image data
x_test, y_test = test['features'] ,test['labels']
x_val, y_val = val['features'] ,val['labels']

#print(x_train.shape) #(34799, 32, 32, 3)
#print(x_test.shape)  #(12630, 32, 32, 3)
#print(x_val.shape)   #(4410, 32, 32, 3)


assert(x_train.shape[0]==y_train.shape[0]),   "Amount of Training images not equal to number of labels"
assert(x_test.shape[0]==y_test.shape[0]),   "Amount of Testing images not equal to number of labels"
assert(x_val.shape[0]==y_val.shape[0]),   "Amount of Validation images not equal to number of labels"
assert(x_train.shape[1:]==(32,32,3)),     "Training image is not the correct size or depth"
assert(x_test.shape[1:]==(32,32,3)),     "Training image is not the correct size or depth"
assert(x_val.shape[1:]==(32,32,3)),     "Training image is not the correct size or depth"

#old code modified

data =  pd.read_csv('german-traffic-signs/signnames.csv')  #store signnames as data frame
#data.replace('No vechiles' , 'vehicles')
#just fixing misspelled data
wrong_Signnames = [ "No passing for vehicles over 3.5 metric tons","No Vehicles","Vechiles over 3.5 metric tons prohibited","End of no passing by vehicles over 3.5 metric ..."]
data.loc[10,["SignName"]] = wrong_Signnames[0]
data.loc[15,["SignName"]] = wrong_Signnames[1]
data.loc[16,["SignName"]] = wrong_Signnames[2]
data.loc[42,["SignName"]] = wrong_Signnames[3]


num_of_samples = []
 
cols = 5
num_classes = 43 #now 43 classes compared to 10 with MNIST
 
# fig, axs = plt.subplots(nrows=num_classes, ncols = cols, figsize=(5, 50))
# fig.tight_layout()  #improves layout (plots with enough distance between them)
# for i in range(cols):
#     for j,row in data.iterrows():     #let's us iterate over data as pairs of :(index,series), row to iterate over series (1D array with data (name, class id,...))
#         x_selected = x_train[y_train == j]    
#         axs[j][i].imshow(x_selected[random.randint(0, len(x_selected - 1)), :, :], cmap=plt.get_cmap("gray"))
#         axs[j][i].axis("off")
#         if i == 2:
#             axs[j][i].set_title("Class Number " + " "+ str(j)+ ":" + row["SignName"])
#             num_of_samples.append(len(x_selected))

import cv2
 
#plt.imshow(x_train[800])
#plt.axis("off")
print(x_train[800].shape)
print(y_train[800])
def grayscale(img):           #convert to grayscale to reduce channels
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img
  
gray_img = grayscale(x_train[800])
#plt.imshow(gray_img)
#plt.axis("off")

#perform histogram equalization 
#normalizes lighting, "spreads it at the ends"
#enhances contrast
#flattens histogram by reassigning grayscale values

def hist_equalization(image):
  image = cv2.equalizeHist(image)
  return image

equalized = hist_equalization(gray_img)

plt.imshow(equalized)
plt.axis("off")

def preprocessing(image):
  image = grayscale(image)
  image = hist_equalization(image)
  image = image/255                #divide by 255 to normalize for smaller variation of pixels (between 0 and 1)
  return image 

x_train = np.array(list(map(preprocessing,x_train)))  #map iterates through entire array and then passes it through specified function
x_test = np.array(list(map(preprocessing,x_test)))    #same for test
x_val = np.array(list(map(preprocessing,x_val)))      #same for validation

#reshape to add depth to process in CNN
x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)
x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)
x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2],1)
from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, zoom_range =0.2, shear_range= 0.1, rotation_range = 10)
#shift shifts images over 
#zoom range is defined by the value -1 (lower boarder = zoom in) to the value +1 (zoom out 1.2)
#shear is angling the image, can be done in x and y direction

datagen.fit(x_train)  #only performs this when requested, to save resources
batches = datagen.flow(x_train, y_train, batch_size = 20)   #requesting for images, creates 20 images everytime it's called, stored in batches
x_batch , y_batch = next(batches)  #calls iterator and retrieves next item for it
fig ,axs = plt.subplots(1,15, figsize = (20,5))
fig.tight_layout()
for i in range (15):
  axs[i].imshow(x_batch[i].reshape(32,32))
  axs[i].axis("off")
#hot encoding
y_train = to_categorical(y_train,43) 
y_test = to_categorical(y_test,43) 
y_val = to_categorical(y_val,43)

def lenet_model():
  model = Sequential()
  model.add(Conv2D(30,(5,5),input_shape= (32,32,1),activation = 'relu')) #30 5x5 filters applied
  #scaled down to 28x28
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Conv2D(15,(3,3),activation = 'relu'))                  
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(Flatten()) #flatten to input in fully connected layer
  model.add(Dense(500,activation = 'relu'))  
  model.add(Dropout(0.5))
  model.add(Dense(num_classes, activation = 'softmax'))
  model.compile(Adam(lr=0.01),loss = 'categorical_crossentropy',metrics = ['accuracy']) 
  return model


#improvement : 
#doubled amount of filters from 30/15 to 60/15
#lr reduced from 0.01 by factor 10
#less paramters as more C layers result in more reduction in image size, leading to less paramters in Fully Connected layer 
#parameter comparison : 296888 vs. 378023 => more parameters
#by adding more conultional we reduced it from over to 500 000 to 378023
def new_model():
  model = Sequential()
  model.add(Conv2D(60,(5,5),input_shape= (32,32,1),activation = 'relu')) #30 5x5 filters applied
  #model.add(Dropout(0.5))
  #num of parameters : (kernel_size*stride+1)*filters
  model.add(Conv2D(60,(5,5),input_shape= (32,32,1),activation = 'relu'))
  #scaled down to 28x28
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Conv2D(30,(3,3),activation = 'relu'))                  #doubled amount of filters from 30/15 to 60/60/30/30
  #model.add(Dropout(0.5))
  model.add(Conv2D(30,(3,3),activation = 'relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(Dropout(0.5))
  model.add(Flatten()) #flatten to input in fully connected layer
  model.add(Dense(500,activation = 'relu'))  
  model.add(Dropout(0.5))
  model.add(Dense(num_classes, activation = 'softmax'))
  model.compile(Adam(lr=0.001),loss = 'categorical_crossentropy',metrics = ['accuracy'])  #lr reduced from 0.01 by factor 10
  return model

model = new_model()
print(model.summary())

#h = model.fit(x_train ,y_train,epochs = 10, validation_data = (x_val,y_val),batch_size=400,verbose = 1,shuffle = 1)
h = model.fit_generator(datagen.flow(x_train ,y_train, batch_size=50)
                        ,steps_per_epoch = 2000, epochs = 10, validation_data = (x_val,y_val),shuffle = 1) #100000 images per epoch
#each epoch now takes about minute compared to a few seconds before
#steps_per_epoch refeers to amount of images generated per epoch

plt.plot(h.history['acc'],label = 'acc')
plt.plot(h.history['val_acc'],label = 'val_acc')
plt.legend()
plt.xlabel('Epoch')

score = model.evaluate(x_test,y_test,verbose = 0)
print('Test score : ',score[0])
print('Test Accuracy : ',score[1])  #just about 0.9 with lenet

import requests
from PIL import Image
url = ['https://c8.alamy.com/comp/G667W0/road-sign-speed-limit-30-kmh-zone-passau-bavaria-germany-G667W0.jpg'
, 'https://c8.alamy.com/comp/A0RX23/cars-and-automobiles-must-turn-left-ahead-sign-A0RX23.jpg',
'https://previews.123rf.com/images/bwylezich/bwylezich1608/bwylezich160800375/64914157-german-road-sign-slippery-road.jpg','https://previews.123rf.com/images/pejo/pejo0907/pejo090700003/5155701-german-traffic-sign-no-205-give-way.jpg', 
       'https://c8.alamy.com/comp/J2MRAJ/german-road-sign-bicycles-crossing-J2MRAJ.jpg']


r = requests.get(url[1], stream=True)
img = Image.open(r.raw)
plt.imshow(img, cmap=plt.get_cmap('gray'))

 
 
#Preprocess image
 
img = np.asarray(img)
img = cv2.resize(img, (32, 32))
img = preprocessing(img)
#plt.imshow(img, cmap = plt.get_cmap('gray'))
print(img.shape)
 
#Reshape reshape
 
img = img.reshape(1, 32, 32, 1)   #reshape to have appropriate size, 1 at position 0 since we have only 1 image
 
#Test image
a = int(model.predict_classes(img))
b = data.iloc[a,1]    #row 1 is where Sign name is placed
print("Predicted sign is : " + str(b))